{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hasaan Mohsin\n",
    "\n",
    "# Lab: Comparing Random Forest and XGBoost modeling performance\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* Use scikit-learn to implement Random Forest and XGBoost regression models\n",
    "* Compare the performances of the two models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, I'll create and measure the relative performances of Random Forest and XGBoost regression models for predicting house prices using the California Housing Dataset.\n",
    "'Performance' means both speed and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the libraries that will be required in this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy==2.2.0 in /opt/conda/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: scikit-learn==1.6.0 in /opt/conda/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.0) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.0) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.0) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.0) (3.6.0)\n",
      "Requirement already satisfied: matplotlib==3.9.3 in /opt/conda/lib/python3.12/site-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.3) (1.17.0)\n",
      "Collecting xgboost==2.1.3\n",
      "  Using cached xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from xgboost==2.1.3) (2.2.0)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost==2.1.3)\n",
      "  Using cached nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from xgboost==2.1.3) (1.17.0)\n",
      "Using cached xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Using cached nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl (289.8 MB)\n",
      "Installing collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.29.2 xgboost-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy==2.2.0\n",
    "!pip install scikit-learn==1.6.0\n",
    "!pip install matplotlib==3.9.3\n",
    "!pip install xgboost==2.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may now start by importing the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the California Housing dataset from URL\n",
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/UZPRFNucrENAFm25csq6eQ/California-housing.csv\")\n",
    "df.head()\n",
    "# # Separate features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: How many observations and features does the dataset have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations: 20640\n",
      "Number of Features: 9\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "N_observations, N_features = df.shape[0], df.shape[1]\n",
    "print('Number of Observations: ' + str(N_observations))\n",
    "print('Number of Features: ' + str(N_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "N_observations, N_features = X.shape\n",
    "print('Number of Observations: ' + str(N_observations))\n",
    "print('Number of Features: ' + str(N_features))\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a moderately sized dataset used for this analysis.  \n",
    "Keep in mind you are only using one dataset so you have to consider that the comparison may change with scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize models\n",
    "In this step you define the number of base estimators, or individual trees, to be used in each model, and then intialize models for Random Forest regression and XGBoost regression.  You'll just use the default parameters to make the performance comparisons. As a part of the performance comparison, we'll also measure the training times for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "n_estimators=100\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=n_estimators, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "# Measure training time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_time_rf = time.time()\n",
    "rf_train_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure training time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "end_time_xgb = time.time()\n",
    "xgb_train_time = end_time_xgb - start_time_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. Use the fitted models to make predictions on the test set. \n",
    "Also, measure the time it takes for each model to make its predictions using the time.time() function to measure the times before and after each model prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1781916618347168\n",
      "0.012375593185424805\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "# yhat_rf = rf.predict(X_train)\n",
    "\n",
    "# Measure prediction time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediction time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "\n",
    "print(rf_pred_time)\n",
    "print(xgb_pred_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "# Measure prediction time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediciton time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:  Calulate the MSE and R^2 values for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.255553781221915\n",
      "0.2225899267544737\n",
      "0.804981661858749\n",
      "0.8301370561019205\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(mse_rf)\n",
    "print(mse_xgb)\n",
    "print(r2_rf)\n",
    "print(r2_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:  Print the MSE and R^2 values for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  MSE = 0.2556, R^2 = 0.8050\n",
      "      XGBoost:  MSE = 0.2226, R^2 = 0.8301\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the MSE and R^2 values that XGBoost is better than Random Forest, but the differences aren't overwhelming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:  Print the timings for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  Training Time = 18.104 seconds, Testing time = 0.178 seconds\n",
      "      XGBoost:  Training Time = 0.661 seconds, Testing time = 0.012 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is very impressive is the difference in computation time between XGBoost and Random Forest for both training and testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you want to generate scatter plots between the predicted and actual values for both models so you can visually evaluate how well each model performs.\n",
    "We'll also plot lines one standard deviation of the test data above and below the ideal line, that is, the line that represents the perfect regressor, where the predictions are all correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6. Calculate the standard deviation of the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "std_y = np. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "``` python\n",
    "# Standard deviation of y_test\n",
    "std_y = np.std(y_test)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediciton time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')\n",
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')\n",
    "std_y = np.std(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Random Forest plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, color=\"blue\",ec='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label=\"perfect model\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label=\"+/-1 Std Dev\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )\n",
    "plt.ylim(0,6)\n",
    "plt.title(\"Random Forest Predictions vs Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# XGBoost plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.5, color=\"orange\",ec='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label=\"perfect model\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label=\"+/-1 Std Dev\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )\n",
    "plt.ylim(0,6)\n",
    "plt.title(\"XGBoost Predictions vs Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models performed very well. Most of their predictions fall within a standard deviation of the target. Interestingly, random forest \"respects\" the upper bound (the maximum value) present in the target by staying within its limits, while XGBoost \"overshoots\", or exceeds this limit. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You're ready to move on to your next lesson.\n",
    "\n",
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/jpgrossman/\" target=\"_blank\">Jeff Grossman</a>\n",
    "\n",
    "### Other Contributors\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/abhishek-gagneja-23051987/\" target=\"_blank\">Abhishek Gagneja</a>\n",
    "\n",
    "<!-- ## Changelog\n",
    "\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|:------------|:------|:------------------|:---------------------------------------|\n",
    "| 2024-11-05 | 1.0  | Jeff Grossman    | Create content | -->\n",
    "\n",
    "\n",
    "\n",
    "## <h3 align=\"center\"> Â© IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "16c894fcd0f379d967c5ce2d915d90efe08ca0580b182d23565c7b762886a39a"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
